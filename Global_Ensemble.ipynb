{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "264a6e77-5848-4476-8933-9efd826184b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.0/317.0 MB 2.0 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting py4j==0.10.9.7\n  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.5/200.5 kB 25.7 MB/s eta 0:00:00\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py): started\n  Building wheel for pyspark (setup.py): finished with status 'done'\n  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488496 sha256=6d4c530b63d385a655149321c869858de1bb641efdf9820b8be335c2a82ef319\n  Stored in directory: /home/spark-b245d5d4-d166-441a-a1e1-ab/.cache/pip/wheels/22/f3/c0/49d7c304ee9ebfd58d8417a140fa93a306ea3d28d19e9af018\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9.7 pyspark-3.5.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56a09d4-df75-497b-85ff-3300d1d9e09e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<SparkContext master=spark://10.139.64.10:7077 appName=Databricks Shell>,\n",
       " <pyspark.sql.session.SparkSession at 0x7f27c9fa64d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sc, spark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34480a76-3a29-432f-810d-22fff2177806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"MLlib lab\") \\\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "# swith the latest spark version to older one so that it tolerates some data format issues\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "\"\"\" \n",
    "in order to avoid \"Parquet column cannot be converted\" error, we need to disable vectorized reader when we have decimal values in our columns. \n",
    "refer to https://learn.microsoft.com/en-us/answers/questions/853861/parquet-column-cannot-be-converted for further info\n",
    "\"\"\"\n",
    "# spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\") \n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f27153c-da02-433b-ad0d-94c01ee599d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc4c7b7-070d-4c67-9089-65cf1e5ad55e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows:1094543412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampNTZType, LongType, DoubleType,IntegerType\n",
    "\"\"\"\n",
    "We have encountered \"Parquet column cannot be converted\" error. As a workaround we decided to loop through directory and ensure there is no column type mismatch by checking file by file.\n",
    "\"\"\"\n",
    "\n",
    "directory = '/mnt/2024-team14/'\n",
    "\n",
    "# List all parquet files\n",
    "parquet_files = dbutils.fs.ls(directory)\n",
    "#print(parquet_files)\n",
    "#weather_file = parquet_files.pop()\n",
    "#taxi_lookup = parquet_files.pop()\n",
    "#json = parquet_files.pop()\n",
    "#traffic = parquet_files.pop()\n",
    "\n",
    "# Loop through directory and check where there is a column type mismatch between files\n",
    "\"\"\"prev_types, curr_types = None, None\n",
    "mismatches = {}\n",
    "for file in parquet_files: \n",
    "  if file.path == \"/mnt/2024-team14/weather_data.csv\": \n",
    "    df1 = spark.read.csv(path) \n",
    "    continue\n",
    "  # Read the Parquet file with schema inference\n",
    "  df = spark.read.parquet(file.path)\n",
    "\n",
    "  if not prev_types and not curr_types:\n",
    "    curr_types = df.dtypes\n",
    "    continue\n",
    "  \n",
    "  prev_types = curr_types\n",
    "  curr_types = df.dtypes\n",
    "\n",
    "  # check each column\n",
    "  for i in range(len(df.columns)):\n",
    "    if prev_types[i] != curr_types[i]:\n",
    "      if not file.name in mismatches:\n",
    "        mismatches[file.name] = [(prev_types[i][0], (prev_types[i][1], curr_types[i][1]))]\n",
    "      else:\n",
    "        mismatches[file.name].append((prev_types[i][0], (prev_types[i][1], curr_types[i][1])))\"\"\"\n",
    "\n",
    "# print(mismatches)\n",
    "schema = StructType([\n",
    "  StructField('hvfhs_license_num', StringType(), nullable=True), \n",
    "  StructField('dispatching_base_num', StringType(), nullable=True), \n",
    "  StructField('originating_base_num', StringType(), nullable=True), \n",
    "  StructField('request_datetime', TimestampNTZType(), nullable=True), \n",
    "  StructField('on_scene_datetime', TimestampNTZType(), nullable=True), \n",
    "  StructField('pickup_datetime', TimestampNTZType(), nullable=True), \n",
    "  StructField('dropoff_datetime', TimestampNTZType(), nullable=True), \n",
    "  StructField('PULocationID', LongType(), nullable=True), \n",
    "  StructField('DOLocationID', LongType(), nullable=True), \n",
    "  StructField('trip_miles', DoubleType(), nullable=True), \n",
    "  StructField('trip_time', LongType(), nullable=True), \n",
    "  StructField('base_passenger_fare', DoubleType(), nullable=True), \n",
    "  StructField('tolls', DoubleType(), nullable=True), \n",
    "  StructField('bcf', DoubleType(), nullable=True), \n",
    "  StructField('sales_tax', DoubleType(), nullable=True), \n",
    "  StructField('congestion_surcharge', DoubleType(), nullable=True), \n",
    "  StructField('airport_fee', IntegerType(), nullable=True), \n",
    "  StructField('tips', DoubleType(), nullable=True), \n",
    "  StructField('driver_pay', DoubleType(), nullable=True), \n",
    "  StructField('shared_request_flag', StringType(), nullable=True), \n",
    "  StructField('shared_match_flag', StringType(), nullable=True), \n",
    "  StructField('access_a_ride_flag', StringType(), nullable=True), \n",
    "  StructField('wav_request_flag', StringType(), nullable=True), \n",
    "  StructField('wav_match_flag', IntegerType(), nullable=True)\n",
    "])\n",
    "# Create empty dataframe\n",
    "union_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "\n",
    "# Process each Parquet file\n",
    "for file in parquet_files:\n",
    "  if file.path == \"dbfs:/mnt/2024-team14/MTA_2020mar_2024apr.csv\":\n",
    "    df3 = spark.read.csv(file.path, header=True)\n",
    "  if file.path == \"dbfs:/mnt/2024-team14/weather_data.csv\":\n",
    "    df1 = spark.read.csv(file.path, header=True)\n",
    "  if file.path == 'dbfs:/mnt/2024-team14/taxi_zone_lookup.csv':\n",
    "    df2 = spark.read.csv(file.path, header=True)\n",
    "  if \"parquet\" in file.path:  \n",
    "    df = spark.read.parquet(file.path)\n",
    "    # Read the Parquet file with schema inference\n",
    "  #df = spark.read.parquet(file.path)\n",
    "\n",
    "    # (column with mismatch, desirable type)\n",
    "  mismatch_col = [\n",
    "      (\"wav_match_flag\", \"string\"), \n",
    "      (\"airport_fee\", \"double\"), \n",
    "      (\"PULocationID\", \"bigint\"), \n",
    "      (\"DOLocationID\", \"bigint\")\n",
    "    ]\n",
    "\n",
    "  df = df.withColumns({c: F.col(c).cast(t) for c, t in mismatch_col})\n",
    "\n",
    "    # Union the casted DataFrame with the union_df\n",
    "  union_df = union_df.union(df)\n",
    "\n",
    "# Revert the variable name after unioning the whole data\n",
    "df = union_df\n",
    "\n",
    "total_rows = df.count()\n",
    "print(f\"Total number of rows:{total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38f1be6c-a435-4a15-927a-e1498343699d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.withColumn(\"day\",F.dayofyear('pickup_datetime'))\n",
    "df=df.withColumn(\"hour\",F.hour('pickup_datetime'))\n",
    "#df=df.withColumn(\"month\",F.month('pickup_datetime'))\n",
    "df=df.withColumn(\"year\",F.year('pickup_datetime'))\n",
    "df=df.withColumn(\"Date\",F.to_date('pickup_datetime'))\n",
    "drop = ['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num', 'request_datetime', 'on_scene_datetime', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'tolls', 'bcf', 'sales_tax', 'congestion_surcharge',\n",
    " 'airport_fee', 'tips', 'driver_pay', 'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag']\n",
    "df = df.drop(*drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78f03f48-9850-4634-9b29-6aed88a70d71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "year_range = (2019, 2025)\n",
    "hds = []\n",
    "for y in range(year_range[0], year_range[1]):\n",
    "  hds += holidays.US(state=\"NY\", years=y).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4485c6c5-fb3a-4689-beeb-6f05cfb97a11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumns({\n",
    "  \"isWeekend\": F.when(F.col(\"Date\").isin(hds) | F.dayofweek(F.col(\"Date\")).isin([1, 7]), 1).otherwise(0),\n",
    "  \"isOvernight\": F.when(F.col(\"hour\").isin(list(range(20, 24))+list(range(0, 6))), 1).otherwise(0)}) \\\n",
    "  .withColumn(\"isRushhour\", \n",
    "              F.when(F.col(\"hour\").isin(list(range(16, 20))) | (F.col(\"isWeekend\") == 0), 1).otherwise(0)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac26fa1-84ed-4e04-8618-60fff6dc2481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.withColumn(\"trip_meters\",F.col('trip_miles')*1609.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4190e0e9-3f0b-4e73-86bb-f70eb9957015",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'TMAX (Degrees Fahrenheit)',\n",
       " 'TMIN (Degrees Fahrenheit)',\n",
       " 'PRCP (Inches)',\n",
       " 'SNOW (Inches)',\n",
       " 'SNWD (Inches)',\n",
       " 'PRCP (mm)',\n",
       " 'SNOW (mm)',\n",
       " 'SNWD (mm)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abafd7e7-e181-4ecd-8ed5-b0a30e2f4c42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter(df.year==2024)\n",
    "df = df.drop(*['Date','trip_miles','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "823f24ae-c3ca-47ba-8700-3ced0e0953ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df =df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06285f01-ed24-4bc7-b075-0912063647a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.DriverStoppedException: Driver down cause: driver state change (exit code: 137)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:465)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "The spark driver has stopped unexpectedly and is restarting. Your notebook will be automatically reattached."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.DriverStoppedException: Driver down cause: driver state change (exit code: 137)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:465)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "# Set the random seed (for reproducibility)\n",
    "seed = 42\n",
    "# Split the DataFrame into training and test sets using a fixed random split\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3], seed=seed)\n",
    "# Print the sizes of the training and test sets\n",
    "print(f\"Training Data Size: {train_df.count()}\")\n",
    "print(f\"Test Data Size: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "866e6d27-a1d0-4a38-9431-d4eec6aabe8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol='base_passenger_fare')\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123a82e2-694f-4e01-b2d5-f051af691418",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler3 = VectorAssembler(\n",
    "    inputCols=['trip_time', 'day', 'isWeekend', 'isOvernight', 'isRushhour', 'trip_meters'],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26633583-7a65-4829-84da-c798cf3d9f79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#vectorAssembler3.transform(train_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1534b2f8-a52e-45c9-8e36-eda73dfc4fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "lr = GBTRegressor(maxDepth=5,labelCol=\"base_passenger_fare\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81964944-3d04-43f7-9b8d-73e1c2b7b51a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "lr_pipeline = Pipeline(stages=[vectorAssembler3, lr])\n",
    "lr_pipeline_model = lr_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af32d119-6d2b-40f4-82d2-f7f4941fd2b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_predictions = lr_pipeline_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(lr_predictions)\n",
    "print(f\"The Root Mean Squared Error: {rmse}\")\n",
    "end = time.time()\n",
    "print(f\"Time Required to run the model: {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d1cce6f-6fb8-4a9a-b2f0-1dd55e0ec399",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lr_pipeline_model.transform(test_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64fb5a98-4c06-436e-90cd-a79378a1102e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
       "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)\n",
       "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)\n",
       "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)\n",
       "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)\n",
       "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
       "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
       "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:105)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.abortRunningSequence(ExecContextState.scala:757)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$shutdown$4(ExecContextState.scala:455)",
        "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)",
        "\tat scala.collection.Iterator.foreach(Iterator.scala:943)",
        "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)",
        "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
        "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)",
        "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
        "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
        "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)",
        "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)",
        "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.shutdown(ExecContextState.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.shutdownContext(ChauffeurState.scala:704)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$clearAllRunningState$4(ChauffeurState.scala:673)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.clearAllRunningState(ChauffeurState.scala:671)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.processDriverStateChange(ChauffeurState.scala:467)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.onDriverStateChange(Chauffeur.scala:1354)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$driverStateOpt$1$adapted(Chauffeur.scala:180)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$goToStopped$4$adapted(DriverDaemonMonitorImpl.scala:210)",
        "\tat scala.collection.immutable.List.foreach(List.scala:431)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.goToStopped(DriverDaemonMonitorImpl.scala:210)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.monitorDriver(DriverDaemonMonitorImpl.scala:360)",
        "\tat com.databricks.spark.chauffeur.DriverDaemonMonitorImpl.$anonfun$job$1(DriverDaemonMonitorImpl.scala:75)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperationWithResultTags(SingletonJob.scala:335)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$4(SingletonJob.scala:395)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:335)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$3(SingletonJob.scala:394)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.$anonfun$run$1(SingletonJob.scala:393)",
        "\tat com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)",
        "\tat com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:387)",
        "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)",
        "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)",
        "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
        "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
        "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "partitions = [1,2,4,8,16,32,64,128,256,512]\n",
    "for i in partitions:\n",
    "  start_time = time.time()\n",
    "  train_df_repartition= train_df.repartition(i).cache()\n",
    "  lr_pipeline_model = lr_pipeline.fit(train_df)\n",
    "  lr_predictions = lr_pipeline_model.transform(test_df)\n",
    "  end_time= time.time()\n",
    "  with open(\"Global_Ensemble_gbt.csv\", \"a\") as f:\n",
    "        print(\n",
    "              f\"{i},{evaluator.evaluate(lr_predictions)},{end - start}\",\n",
    "              file=f,\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Global_Ensemble",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
